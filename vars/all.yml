---
# ================================================================
# GLOBAL CONFIGURATION — edit this file before running
# ================================================================

# ── GCP Settings ─────────────────────────────────────────────────
gcp_project_id: "project-4b3eaec5-c5a4-4b56-954" # GCP project ID
service_account_file: "/Users/macbookpro/Desktop/k8s-gcp-automation/credentials/service-account.json" # Path to SA JSON key
adc_file: "/Users/macbookpro/Desktop/k8s-gcp-automation/credentials/adc_file.json"

# ── VM Defaults (overridable per node_group) ──────────────────────
gcp_machine_type: "e2-standard-2" # 2 vCPU / 8 GB RAM
gcp_image_family: "ubuntu-2204-lts"
gcp_image_project: "ubuntu-os-cloud"
gcp_disk_size_gb: 50
gcp_disk_type: "pd-standard"

# ── Kubernetes Firewall Rules ─────────────────────────────────────
k8s_firewall_rules:

  # Internal cluster traffic (all nodes talk to each other freely)
  - name: "{{ cluster_name }}-allow-internal"
    protocol: tcp
    ports: ["0-65535"]
    tags: ["{{ cluster_name }}-node"]
    source_ranges: ["10.0.0.0/8"]
    description: "Allow all internal TCP between cluster nodes"

  - name: "{{ cluster_name }}-allow-internal-udp"
    protocol: udp
    ports: ["0-65535"]
    tags: ["{{ cluster_name }}-node"]
    source_ranges: ["10.0.0.0/8"]
    description: "Allow all internal UDP between cluster nodes (flannel/calico/weave)"

  - name: "{{ cluster_name }}-allow-internal-icmp"
    protocol: icmp
    ports: []
    tags: ["{{ cluster_name }}-node"]
    source_ranges: ["10.0.0.0/8"]
    description: "Allow ICMP between cluster nodes"

  # Control plane (masters)
  - name: "{{ cluster_name }}-allow-apiserver"
    protocol: tcp
    ports: ["6443"]
    tags: ["{{ cluster_name }}-master"]
    source_ranges: ["0.0.0.0/0"]
    description: "Kubernetes API server"

  - name: "{{ cluster_name }}-allow-etcd"
    protocol: tcp
    ports: ["2379", "2380"]
    tags: ["{{ cluster_name }}-master"]
    source_ranges: ["10.0.0.0/8"]
    description: "etcd server client and peer communication"

  - name: "{{ cluster_name }}-allow-controller-manager"
    protocol: tcp
    ports: ["10257"]
    tags: ["{{ cluster_name }}-master"]
    source_ranges: ["10.0.0.0/8"]
    description: "kube-controller-manager"

  - name: "{{ cluster_name }}-allow-scheduler"
    protocol: tcp
    ports: ["10259"]
    tags: ["{{ cluster_name }}-master"]
    source_ranges: ["10.0.0.0/8"]
    description: "kube-scheduler"

  # Workers
  - name: "{{ cluster_name }}-allow-kubelet"
    protocol: tcp
    ports: ["10250"]
    tags: ["{{ cluster_name }}-node"]
    source_ranges: ["10.0.0.0/8"]
    description: "Kubelet API (masters need to reach workers)"

  - name: "{{ cluster_name }}-allow-nodeport"
    protocol: tcp
    ports: ["30000-32767"]
    tags: ["{{ cluster_name }}-node"]
    source_ranges: ["0.0.0.0/0"]
    description: "Kubernetes NodePort services"

  # SSH
  - name: "{{ cluster_name }}-allow-ssh"
    protocol: tcp
    ports: ["22"]
    tags: ["{{ cluster_name }}-node"]
    source_ranges: ["0.0.0.0/0"]
    description: "SSH access to all cluster nodes"
  
  # Ingress HTTP/HTTPS
  - name: "{{ cluster_name }}-allow-http-https"
    protocol: tcp
    ports: ["80", "443"]
    tags: ["{{ cluster_name }}-node"]
    source_ranges: ["0.0.0.0/0"]
    description: "Allow HTTP/HTTPS traffic for ingress"

# ── Cluster Identity ──────────────────────────────────────────────
cluster_name: "ha-k8s"

# ── Node Groups — THE only place you change topology ─────────────
# Each entry produces `count` VMs named: <cluster_name>-<role>-N
#
# Scaling examples:
#   5 masters:  change count: 3 → 5
#   3 workers:  change count: 2 → 3
#   New role:   add a new list item (e.g. infra, gpu-worker)
#
# Per-group overrides (optional — falls back to gcp_* defaults):
#   machine_type, disk_size_gb, disk_type, tags
node_groups:
  - role: master
    count: 3
    region: "asia-northeast3"
    subnet_cidr: "10.10.1.0/24"       # defines the IP address range that VMs in that subnet get their private IPs from.
    zone: "asia-northeast3-a"
    machine_type: "{{ gcp_machine_type }}" # override here for different sizing
    disk_size_gb: "{{ gcp_disk_size_gb }}"
    tags:
      - "{{ cluster_name }}-node"
      - "{{ cluster_name }}-master"

  - role: worker
    count: 2
    region: "asia-northeast1"   # different region
    subnet_cidr: "10.10.2.0/24"
    zone: "asia-northeast1-b"
    machine_type: "{{ gcp_machine_type }}"
    disk_size_gb: "{{ gcp_disk_size_gb }}"
    tags:
      - "{{ cluster_name }}-node"
      - "{{ cluster_name }}-worker"

# ── SSH ───────────────────────────────────────────────────────────
ssh_user: "k8s-cluster-key"
ssh_private_key: "/Users/macbookpro/Desktop/k8s-gcp-automation/credentials/k8s-ssh-adc-key"
ssh_public_key:  "/Users/macbookpro/Desktop/k8s-gcp-automation/credentials/k8s-ssh-adc-key.pub"

# ── Kubernetes ────────────────────────────────────────────────────
kubespray_version: "v2.29.0"
kubespray_repo: "https://github.com/kubernetes-sigs/kubespray"
kube_version: "1.31.1"          
kube_vip_enabled: false 
kube_network_plugin: "calico"
kubeconfig_path: "/home/{{ ssh_user }}/.kube/config"
# ── ArgoCD ────────────────────────────────────────────────────────
argocd_version: "v2.10.3"
argocd_namespace: "argocd"
argocd_admin_password: "ChangeMe123!" # Change this!

# ── K8s Dashboard ────────────────────────────────────────────────
dashboard_namespace: "kube-system"
