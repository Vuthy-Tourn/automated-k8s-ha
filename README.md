# ğŸš€ HA Kubernetes Cluster â€” Full Automation
### GCP + Ansible + Kubespray + ArgoCD + K8s Dashboard + Cloudflare DNS

---

## ğŸ“ Architecture & Pipeline

```
Your Local Machine (Ansible Controller)
â”‚
â”œâ”€ STAGE 1+2 â”€â”€â–º GCP API (service account)
â”‚                  Create VPC + Subnet + Firewall rules
â”‚                  Provision 5 VMs (Ubuntu 22.04, e2-standard-2)
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â”‚  us-central1-a (masters zone)           â”‚
â”‚                  â”‚   ha-k8s-master-1  10.10.0.x  â—„â”€ kube-vip (10.10.0.100)
â”‚                  â”‚   ha-k8s-master-2  10.10.0.x            â”‚
â”‚                  â”‚   ha-k8s-master-3  10.10.0.x            â”‚
â”‚                  â”‚                                         â”‚
â”‚                  â”‚  us-central1-b (workers zone)           â”‚
â”‚                  â”‚   ha-k8s-worker-1  10.10.0.x            â”‚
â”‚                  â”‚   ha-k8s-worker-2  10.10.0.x            â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                  Write â†’ inventory/hosts.ini (dynamic, from real IPs)
â”‚                  Write â†’ inventory/kubespray-hosts.yaml
â”‚
â”œâ”€ STAGE 3 â”€â”€â”€â”€â”€â–º All 5 VMs (parallel)
â”‚                  Disable swap, sysctl, kernel modules
â”‚                  Install packages, set /etc/hosts, NTP
â”‚
â”œâ”€ STAGE 4 â”€â”€â”€â”€â”€â–º master1 only
â”‚                  Clone Kubespray v2.24.0
â”‚                  Push inventory + group_vars
â”‚                  master1 â†’ ansible-playbook cluster.yml
â”‚                       â†’ installs K8s on all 5 via internal IPs
â”‚
â”œâ”€ STAGE 5 â”€â”€â”€â”€â”€â–º master1 â†’ local
â”‚                  Fetch /etc/kubernetes/admin.conf
â”‚                  Patch server: to master1 external IP
â”‚                  Install kubectl + helm on local if missing
â”‚
â”œâ”€ STAGE 6 â”€â”€â”€â”€â”€â–º local â†’ K8s cluster
â”‚                  Deploy ArgoCD (+ ingress + patch password)
â”‚                  Deploy K8s Dashboard (helm + admin token)
â”‚
â””â”€ STAGE 7 â”€â”€â”€â”€â”€â–º Cloudflare API
                   k8s-dashboard.example.com â†’ worker-1 external IP
                   argocd.example.com        â†’ worker-1 external IP
```

---

## âš¡ Quick Start

### 1. Prerequisites

```bash
# Install Python dependencies
pip3 install -r requirements.txt

# Install Ansible Galaxy collections (GCP + extras)
ansible-galaxy collection install -r requirements.yml
```

### 2. GCP Service Account

```bash
# In GCP Console â†’ IAM â†’ Service Accounts â†’ Create
# Grant these roles:
#   Compute Admin
#   Service Account User
#   DNS Admin (if managing GCP DNS â€” we use Cloudflare here)

# Download JSON key â†’ save as:
cp ~/Downloads/your-sa-key.json files/sa-key.json
```

### 3. Configure Variables

Edit **`group_vars/all.yml`** â€” minimum required changes:

```yaml
gcp_project:          "your-actual-gcp-project-id"
gcp_service_account:  "files/sa-key.json"
gcp_region:           "us-central1"          # change if needed
gcp_zone_masters:     "us-central1-a"
gcp_zone_workers:     "us-central1-b"

cluster_name:         "ha-k8s"               # used as VM name prefix

cloudflare_zone:      "yourdomain.com"
cloudflare_api_token: "your-cf-token"
argocd_admin_password: "YourSecurePassword!"
```

### 4. Cloudflare API Token

Go to https://dash.cloudflare.com/profile/api-tokens â†’ Create Token

Permissions needed:
- `Zone â†’ DNS â†’ Edit`
- `Zone â†’ Zone â†’ Read`
- Include: your specific zone

### 5. Run Everything ğŸ¯

```bash
# Full pipeline â€” one command, ~35-45 minutes total
ansible-playbook site.yml
```

---

## ğŸ›ï¸ Run Individual Stages

```bash
# Stage 1+2: Provision GCP VMs only
ansible-playbook site.yml --tags provision

# Stage 3: Prepare nodes only (VMs must exist)
ansible-playbook site.yml --tags prepare

# Stage 4+5: Kubespray + fetch kubeconfig
ansible-playbook site.yml --tags kubespray

# Stage 6: Deploy apps only (cluster must be running)
ansible-playbook site.yml --tags apps

# Stage 6a: ArgoCD only
ansible-playbook site.yml --tags argocd

# Stage 6b: Dashboard only
ansible-playbook site.yml --tags dashboard

# Stage 7: DNS only
ansible-playbook site.yml --tags dns

# Skip provisioning if VMs already exist
ansible-playbook site.yml --skip-tags provision
```

---

## ğŸ“ Project Structure

```
k8s-gcp-automation/
â”‚
â”œâ”€â”€ site.yml                        â† ğŸ¯ Run this (full pipeline)
â”œâ”€â”€ teardown.yml                    â† ğŸ’£ Destroy everything on GCP
â”œâ”€â”€ ansible.cfg                     â† Ansible settings
â”œâ”€â”€ requirements.txt                â† Python deps (pip install)
â”œâ”€â”€ requirements.yml                â† Ansible collections
â”‚
â”œâ”€â”€ group_vars/
â”‚   â””â”€â”€ all.yml                     â† âœï¸  ALL CONFIG LIVES HERE
â”‚
â”œâ”€â”€ inventory/                      â† Auto-generated, do not edit
â”‚   â”œâ”€â”€ hosts.ini                   â† Written after GCP provision
â”‚   â””â”€â”€ kubespray-hosts.yaml        â† Written after GCP provision
â”‚
â”œâ”€â”€ files/
â”‚   â”œâ”€â”€ sa-key.json                 â† GCP service account key (you add)
â”‚   â”œâ”€â”€ k8s-ssh-key                 â† Auto-generated SSH private key
â”‚   â””â”€â”€ k8s-ssh-key.pub             â† Auto-generated SSH public key
â”‚
â”œâ”€â”€ kubeconfig/                     â† Written after cluster install
â”‚   â”œâ”€â”€ admin.conf                  â† kubectl config
â”‚   â””â”€â”€ dashboard-token.txt         â† K8s Dashboard login token
â”‚
â””â”€â”€ roles/
    â”œâ”€â”€ gcp-provision/              â† Create VMs + write inventory
    â”œâ”€â”€ prepare-nodes/              â† OS prep on all 5 nodes
    â”œâ”€â”€ kubespray-deploy/           â† master1 runs Kubespray
    â”œâ”€â”€ fetch-kubeconfig/           â† Pull kubeconfig to local
    â”œâ”€â”€ argocd/                     â† Install ArgoCD
    â”œâ”€â”€ k8s-dashboard/              â† Install K8s Dashboard
    â””â”€â”€ cloudflare-dns/             â† Create DNS records
```

---

## ğŸŒ Accessing Your Cluster

```bash
# After site.yml completes:
export KUBECONFIG=$(pwd)/kubeconfig/admin.conf

kubectl get nodes -o wide
kubectl get pods -A
kubectl get svc -A
```

| App | URL | Login |
|-----|-----|-------|
| **K8s Dashboard** | `https://k8s-dashboard.example.com` | Token from `kubeconfig/dashboard-token.txt` |
| **ArgoCD** | `https://argocd.example.com` | `admin` / value from `argocd_admin_password` |

---

## ğŸ” Troubleshooting

```bash
# Check all nodes reachable
ansible all -m ping -i inventory/hosts.ini

# Verbose run
ansible-playbook site.yml -vvv

# Check Kubespray log on master1
ssh -i files/k8s-ssh-key ubuntu@<master1-ip> \
  "tail -100 ~/kubespray-install.log"

# Check cluster events
kubectl get events -A --sort-by='.lastTimestamp'

# Check ingress controller
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx

# Check ArgoCD pods
kubectl get pods -n argocd

# Re-run only failed stage
ansible-playbook site.yml --tags apps
```

## ğŸ’£ Teardown

```bash
# Destroys all GCP VMs, network, firewall rules
ansible-playbook teardown.yml
```

---

## â±ï¸ Expected Timeline

| Stage | Duration |
|-------|----------|
| GCP VM provisioning | 3â€“5 min |
| Node preparation | 3â€“5 min |
| Kubespray K8s install | 20â€“30 min |
| Kubeconfig fetch | < 1 min |
| ArgoCD + Dashboard | 3â€“5 min |
| Cloudflare DNS | < 1 min |
| **Total** | **~30â€“45 min** |

---

## ğŸ”’ GCP Firewall Summary

| Rule | Ports | Source | Target |
|------|-------|--------|--------|
| allow-internal | ALL | `10.10.0.0/24` | all nodes |
| allow-ssh | 22 | `0.0.0.0/0` | all nodes |
| allow-k8s-api | 6443 | `0.0.0.0/0` | masters |
| allow-http-https | 80, 443 | `0.0.0.0/0` | workers |
| allow-nodeport | 30000-32767 | `0.0.0.0/0` | all nodes |
