# üöÄ HA Kubernetes Cluster ‚Äî Full Automation

### GCP + Ansible + Kubespray + ArgoCD + K8s Dashboard + Cloudflare DNS

---

## üìê Architecture & Pipeline

```
Your Local Machine (Ansible Controller)
‚îÇ
‚îú‚îÄ STAGE 1+2 ‚îÄ‚îÄ‚ñ∫ GCP API (Application Default Credentials)
‚îÇ                  Create VPC + Subnet + Firewall rules
‚îÇ                  Provision 5 VMs (Ubuntu 22.04, e2-standard-2)
‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ‚îÇ  us-central1-a (masters zone)           ‚îÇ
‚îÇ                  ‚îÇ   ha-k8s-master-1  10.10.0.x            ‚îÇ
‚îÇ                  ‚îÇ   ha-k8s-master-2  10.10.0.x            ‚îÇ
‚îÇ                  ‚îÇ   ha-k8s-master-3  10.10.0.x            ‚îÇ
‚îÇ                  ‚îÇ                                         ‚îÇ
‚îÇ                  ‚îÇ  us-central1-b (workers zone)           ‚îÇ
‚îÇ                  ‚îÇ   ha-k8s-worker-1  10.10.0.x            ‚îÇ
‚îÇ                  ‚îÇ   ha-k8s-worker-2  10.10.0.x            ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ                  Write ‚Üí inventory/hosts.ini (dynamic, from real IPs)
‚îÇ                  Write ‚Üí inventory/kubespray-hosts.yaml
‚îÇ
‚îú‚îÄ STAGE 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ All 5 VMs (parallel)
‚îÇ                  Disable swap, sysctl, kernel modules
‚îÇ                  Install packages, set /etc/hosts, NTP
‚îÇ
‚îú‚îÄ STAGE 4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ master1 only
‚îÇ                  Clone Kubespray v2.24.0
‚îÇ                  Push inventory + group_vars
‚îÇ                  master1 ‚Üí ansible-playbook cluster.yml
‚îÇ                       ‚Üí installs K8s on all 5 via internal IPs
‚îÇ
‚îú‚îÄ STAGE 5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ master1 ‚Üí local
‚îÇ                  Fetch /etc/kubernetes/admin.conf
‚îÇ                  Patch server: to master1 external IP
‚îÇ                  Install kubectl + helm on local if missing
‚îÇ
‚îú‚îÄ STAGE 6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ local ‚Üí K8s cluster
‚îÇ                  Deploy ArgoCD (+ ingress + patch password)
‚îÇ                  Deploy K8s Dashboard (helm + admin token)
‚îÇ
‚îî‚îÄ STAGE 7 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Cloudflare API
                   k8s-dashboard.example.com ‚Üí worker-1 external IP
                   argocd.example.com        ‚Üí worker-1 external IP
```

---

## ‚ö° Quick Start

### 1. Prerequimains

```bash
# Install Python dependencies
pip3 install -r requirements.txt

# Install Ansible Galaxy collections (GCP + extras)
ansible-galaxy collection install -r requirements.yml
```

### 2. GCP Authentication ‚Äî Application Default Credentials (ADC)

This project uses **Application Default Credentials (ADC)** via `adc_file` for GCP authentication ‚Äî no service account JSON key is required.

**Option A ‚Äî User credentials (recommended for local development):**

```bash
gcloud auth application-default login
```

This generates a credentials file at `~/.config/gcloud/application_default_credentials.json`.

**Option B ‚Äî Service account impersonation:**

```bash
gcloud auth application-default login --impersonate-service-account=SA_EMAIL
```

**Then set the path in `vars/all.yml`:**

```yaml
# Point adc_file to your ADC credentials file
adc_file: "~/.config/gcloud/application_default_credentials.json"
```

> **Note:** The account or service account used must have the following IAM roles:
> - `Compute Admin`
> - `Service Account User`

### 3. Configure Variables

Edit **`vars/all.yml`** ‚Äî minimum required changes:

```yaml
gcp_project_id: "your-actual-gcp-project-id"
adc_file: "~/.config/gcloud/application_default_credentials.json"  # path to ADC credentials
gcp_region: "us-central1"        # change if needed
gcp_zone_masters: "us-central1-a"
gcp_zone_workers: "us-central1-b"

cluster_name: "ha-k8s"           # used as VM name prefix

cloudflare_zone: "yourdomain.com"
cloudflare_api_token: "your-cf-token"
argocd_admin_password: "YourSecurePassword!"
```

### 4. Cloudflare API Token

Go to https://dash.cloudflare.com/profile/api-tokens ‚Üí Create Token

Permissions needed:

- `Zone ‚Üí DNS ‚Üí Edit`
- `Zone ‚Üí Zone ‚Üí Read`
- Include: your specific zone

### 5. Run Everything üéØ

```bash
# Full pipeline ‚Äî one command, ~35-45 minutes total
ansible-playbook main.yml
```

---

## üéõÔ∏è Run Individual Stages

```bash
# Stage 1+2: Provision GCP VMs only
ansible-playbook main.yml --tags provision

# Stage 3: Prepare nodes only (VMs must exist)
ansible-playbook main.yml --tags prepare

# Stage 4+5: Kubespray + fetch kubeconfig
ansible-playbook main.yml --tags kubespray

# Stage 6: Deploy apps only (cluster must be running)
ansible-playbook main.yml --tags apps

# Stage 6a: ArgoCD only
ansible-playbook main.yml --tags argocd

# Stage 6b: Dashboard only
ansible-playbook main.yml --tags dashboard

# Stage 7: DNS only
ansible-playbook main.yml --tags dns

# Skip provisioning if VMs already exist
ansible-playbook main.yml --skip-tags provision
```

---

## üìÅ Project Structure

```
k8s-gcp-automation/
‚îÇ
‚îú‚îÄ‚îÄ README.md                       ‚Üê üìù Project overview / instructions
‚îú‚îÄ‚îÄ ansible.cfg                     ‚Üê ‚öôÔ∏è Ansible configuration
‚îú‚îÄ‚îÄ auto_push.sh                     ‚Üê üîÑ Helper script to push changes or run plays
‚îú‚îÄ‚îÄ Justfile                         ‚Üê üõ† Automation helper via just
‚îú‚îÄ‚îÄ requirements.txt                 ‚Üê üêç Python deps (pip install)
‚îú‚îÄ‚îÄ requirements.yml                 ‚Üê üì¶ Ansible collections
‚îÇ
‚îú‚îÄ‚îÄ credentials/                     ‚Üê üîë Secrets for SSH (ADC managed by gcloud)
‚îÇ   ‚îú‚îÄ‚îÄ k8s-ssh-key                  ‚Üê üîê SSH private key (auto-generated)
‚îÇ   ‚îî‚îÄ‚îÄ k8s-ssh-key.pub              ‚Üê üì¨ SSH public key (auto-generated)
‚îÇ
‚îú‚îÄ‚îÄ inventory/                       ‚Üê üìã Auto-generated inventory, do not edit manually
‚îÇ   ‚îú‚îÄ‚îÄ inventory.ini                 ‚Üê üñ• Nodes & IPs (dynamic hosts)
‚îÇ   ‚îî‚îÄ‚îÄ node_info.json                ‚Üê üåê Node info (internal/external IPs, roles)
‚îÇ
‚îú‚îÄ‚îÄ playbooks/                        ‚Üê üìú Main playbooks
‚îÇ   ‚îú‚îÄ‚îÄ main.yml                      ‚Üê ‚ñ∂Ô∏è Entry point (run Kubespray deploy / orchestration)
‚îÇ   ‚îî‚îÄ‚îÄ tasks/
‚îÇ       ‚îú‚îÄ‚îÄ create-gcp.yml            ‚Üê ‚òÅÔ∏è GCP VM provisioning
‚îÇ       ‚îî‚îÄ‚îÄ destroy-gcp.yml           ‚Üê ‚ùå Tear down all GCP infrastructure
‚îÇ
‚îú‚îÄ‚îÄ templates/                        ‚Üê üìÑ Templates for dynamic files
‚îÇ   ‚îú‚îÄ‚îÄ dynamic-hosts.ini.j2          ‚Üê üñ• Jinja template for dynamic inventory.ini
‚îÇ   ‚îú‚îÄ‚îÄ kubespray-hosts.yaml.j2       ‚Üê üèó Jinja template for Kubespray hosts.yaml
‚îÇ   ‚îî‚îÄ‚îÄ startup-script.sh.j2          ‚Üê ‚ö° Startup script run on VM boot
‚îÇ
‚îú‚îÄ‚îÄ roles/                            ‚Üê üéõ Ansible roles
‚îÇ   ‚îú‚îÄ‚îÄ kubespray-deploy/             ‚Üê üèó Master1 runs Kubespray cluster deployment
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.yml              ‚Üê ‚ñ∂Ô∏è Role tasks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Justfile.j2           ‚Üê üõ† Justfile template for Kubespray
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ addons.yml.j2         ‚Üê ‚ûï Optional addons manifest
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ etcd.yml.j2           ‚Üê üóÑ ETCD manifest template
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ inventory.ini.j2      ‚Üê üñ• Dynamic inventory template
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ k8s-cluster.yml.j2    ‚Üê üèó Cluster YAML template
‚îÇ   ‚îú‚îÄ‚îÄ prepare-nodes/                ‚Üê üñ• Prepare OS / dependencies on all nodes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ main.yml
‚îÇ   ‚îú‚îÄ‚îÄ argocd/                       ‚Üê üöÄ Install ArgoCD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ argocd-ingress.yaml.j2
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ argocd-nodeport.yaml.j2
‚îÇ   ‚îú‚îÄ‚îÄ k8s-dashboard/                ‚Üê üñ• Install Kubernetes Dashboard
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ dashboard-admin.yaml.j2
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ dashboard-ingress.yaml.j2
‚îÇ   ‚îî‚îÄ‚îÄ cloudflare-dns/               ‚Üê üåê Create DNS records via Cloudflare
‚îÇ       ‚îî‚îÄ‚îÄ tasks/
‚îÇ           ‚îî‚îÄ‚îÄ main.yml
‚îÇ
‚îú‚îÄ‚îÄ secrets/                          ‚Üê üîí Vault / become password storage
‚îÇ   ‚îî‚îÄ‚îÄ vault_pass.txt                ‚Üê üóù Vault password
‚îÇ
‚îî‚îÄ‚îÄ vars/                             ‚Üê ‚úèÔ∏è Variables for all roles / environments
    ‚îú‚îÄ‚îÄ all.yml                        ‚Üê üè∑ Global vars (includes adc_file path)
    ‚îú‚îÄ‚îÄ cloudflare_vars.yml            ‚Üê üåê Cloudflare DNS vars
    ‚îî‚îÄ‚îÄ secrets.yml                    ‚Üê üîë Vaulted secrets variables
```

---

## üîê GCP Authentication Details

All GCP tasks use the `adc_file` variable, which points to an [Application Default Credentials](https://cloud.google.com/docs/authentication/application-default-credentials) JSON file. This is passed to the `google.cloud.*` Ansible modules via the `auth_kind: "serviceaccount"` or `auth_kind: "application"` parameter ‚Äî no hardcoded service account key file is needed.

**Example usage in a GCP task:**

```yaml
- name: Create GCP instance
  google.cloud.gcp_compute_instance:
    name: "{{ instance_name }}"
    project: "{{ gcp_project_id }}"
    zone: "{{ gcp_zone_masters }}"
    auth_kind: application
    credentials_file: "{{ adc_file }}"
    ...
```

> If `adc_file` is set to the default gcloud ADC path (`~/.config/gcloud/application_default_credentials.json`), no further setup is needed after running `gcloud auth application-default login`.

---

## üåê Accessing Your Cluster

```bash
# After main.yml completes:
export KUBECONFIG=$(pwd)/kubeconfig/admin.conf

kubectl get nodes -o wide
kubectl get pods -A
kubectl get svc -A
```

| App               | URL                                 | Login                                        |
| ----------------- | ----------------------------------- | -------------------------------------------- |
| **K8s Dashboard** | `https://k8s-dashboard.example.com` | Token from `kubeconfig/dashboard-token.txt`  |
| **ArgoCD**        | `https://argocd.example.com`        | `admin` / value from `argocd_admin_password` |

---

## üîç Troubleshooting

```bash
# Check all nodes reachable
ansible all -m ping -i inventory/hosts.ini

# Verbose run
ansible-playbook main.yml -vvv

# Check Kubespray log on master1
ssh -i credentials/k8s-ssh-key ubuntu@<master1-ip> \
  "tail -100 ~/kubespray-install.log"

# Check cluster events
kubectl get events -A --sort-by='.lastTimestamp'

# Check ingress controller
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx

# Check ArgoCD pods
kubectl get pods -n argocd

# Re-run only failed stage
ansible-playbook main.yml --tags apps

# Verify ADC credentials are valid
gcloud auth application-default print-access-token
```

## üí£ Destroy

```bash
# Destroys all GCP VMs, network, firewall rules
ansible-playbook tasks/destroy-gcp.yml
```

---

## ‚è±Ô∏è Expected Timeline

| Stage                 | Duration       |
| --------------------- | -------------- |
| GCP VM provisioning   | 3‚Äì5 min        |
| Node preparation      | 3‚Äì5 min        |
| Kubespray K8s install | 20‚Äì30 min      |
| Kubeconfig fetch      | < 1 min        |
| ArgoCD + Dashboard    | 3‚Äì5 min        |
| Cloudflare DNS        | < 1 min        |
| **Total**             | **~30‚Äì45 min** |

---

## üîí GCP Firewall Summary

| Rule             | Ports       | Source         | Target    |
| ---------------- | ----------- | -------------- | --------- |
| allow-internal   | ALL         | `10.10.0.0/24` | all nodes |
| allow-ssh        | 22          | `0.0.0.0/0`    | all nodes |
| allow-k8s-api    | 6443        | `0.0.0.0/0`    | masters   |
| allow-http-https | 80, 443     | `0.0.0.0/0`    | workers   |
| allow-nodeport   | 30000-32767 | `0.0.0.0/0`    | all nodes |